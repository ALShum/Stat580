\documentclass{article}
\usepackage{url}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage[margin=0.70in]{geometry}
\setlength{\parindent}{0in}

\title{Stat580 - Homework 1}
\author{Alex Shum}
\begin{document}
\maketitle

\section*{Problem 1}
$X_1, X_2, \dots, X_n \sim Unif(0,1)$.  \\
$(\Sigma_{i=1}^n X_i) mod 1 = \Sigma_{i=1}^n X_i - \lfloor \Sigma_{i=1}^n \rfloor \sim Unif(0,1)$. \\
\\
Proof: 

\section*{Problem 2}
Let $F$ be a cumulative distribution function and let $F^{-1} = min\{x | F(x) \ge u\}$.  If $U \sim Unif(0,1)$ then $F^{-1}(U) \sim F$.  We start with the cumulative distribution function for $F^{-1}(U)$: $P(F^{-1}(U) \le x)$
\begin{align*}
\text{Applying F to both sides (F is monotonic): }& P(F^{-1}(U) \le x) = P(U \le F(x))\\
\text{But since U is uniform: }& P(U \le F(x)) = F(x)
\end{align*}

\section*{Problem 3}
\subsection*{Part a}
We know that $U_1, U_2 \sim Unif(0,1)$ and $X = \sqrt{-2log(U_1)}cos(2\pi U_2)$ and $Y = \sqrt{-2log(U_1)}sin(2\pi U_1)$.  We will transform $U_1$ and $U_2$ using the above functions and show that it yields a normal.\\
\begin{align*}
X = \sqrt{-2log(U_1)}cos(2\pi U_2) &\text{ and } Y = \sqrt{-2log(U_1)}sin(2\pi U_1) \\
X^2 + Y^2 = -2log(U_1) &\longrightarrow U_1 = exp\{\frac{-1}{2} (X^2 + Y^2) \} \\
\frac{Y}{X} = tan(2\pi U_2) &\longrightarrow U_2 = \frac{1}{2\pi} tan^{-1}(\frac{Y}{X}) \\
|J| = |det \begin{bmatrix}\frac{\partial U_1}{\partial X} & \frac{\partial U_1}{\partial Y} \\ 
                          \frac{\partial U_2}{\partial X} & \frac{\partial U_2}{\partial Y} \end{bmatrix}|
   &= |\begin{bmatrix} exp\{ \frac{-1}{2}(X^2 + Y^2) \} (-X) & exp\{ \frac{-1}{2}(X^2 + Y^2) \} (-Y) \\ 
                       \frac{1}{2\pi} \frac{X^2}{X^2 + Y^2} \frac{-Y}{X^2} & 
                       \frac{1}{2\pi} \frac{X^2}{X^2 + Y^2} \frac{1}{X}\end{bmatrix}| \\
                      &= \frac{1}{2\pi} \frac{X^2}{X^2 + Y^2} exp\{-\frac{X^2 + Y^2}{2} \} (1 + \frac{Y^2}{X^2}) \\
   &= \frac{1}{2\pi} exp\{-\frac{X^2 + Y^2}{2} \} \\
   &= \frac{1}{\sqrt{2\pi}}exp\{-X^2 /2 \} \frac{1}{\sqrt{2\pi}}exp\{-Y^2 / 2 \} 
\end{align*}
Thus we have that $f_{X,Y}(x,y) = \frac{1}{\sqrt{2\pi}}exp\{-x^2 /2 \} \frac{1}{\sqrt{2\pi}}exp\{-y^2 / 2 \}$ thus we have two independent standard normal variables.

\subsection*{Part b}

\section*{Problem 4}
<<sim, echo=FALSE, cache=TRUE, results='none'>>=
library(ggplot2)
d = 1:20
tail = function(d) {
  U1 = runif(100000,0,1)
  U2 = runif(100000,0,1)
  X = sqrt(d^2 - 2*log(U1))
  sum(U2*X <= d)/100000
}

naive = function(d) {
  R = rnorm(100000,0,1)
  sum(R <= d)/100000
}

a = sapply(d, tail)
b = sapply(d, naive)
@
We sampled from a standard normal tail as follows: we generated 1,000,000 iid samples from $U_1 \sim Unif(0,1)$ and 1,000,000 iid samples from $U_2 \sim Unif(0,1)$.  Then we accept if $U_2 \sqrt{d^2 - 2log(U_1)} \le d$.  We tried $d$ from 1 to 20.  We repeated this experiment by generating 1,000,000 iid samples from $X \sim N(0,1)$ and we accepted if $X \le d$.  \\
\\
We found that when we sample directly from standard normal we accept 100$\%$ of the time when $d > 4$.  When we sampled using the uniforms as described above we found that as $d$ increases the acceptance probability increases but even with $d = 20$ we did not have a 100$\%$ acceptance rate.  With 1,000,000 samples we still rejected about 2200 times.

\section*{Problem 5}
\subsection*{Part a}
The following is a basic outline of our algorithm.  $(A,R,C)$ are the same triples as described in the prompt.  Note that we index the matrix and the vector starting from $index = 0$.  If we want $y_j$, the $j$th element of $y = Wx$.  We must find the $j$th row of our matrix $W$ and multiply with the correct element in vector $x$:
\begin{enumerate}
\item Iterate through the columns (elements in $C$).
\item For each column $i$, find the rows of non-zero elements.
\item If the element in row $j$ is non-zero we multiply it with the $i$th element in $x$.
\end{enumerate}
We include the following pseudo code:
\begin{verbatim}
sum = 0;
r = correct row;
for(int i = 0; i < c.length - 1; i++) {
  for(int j = C[i]; j < C[i + 1]; j++) {
    if(R[j] == r) sum = sum + x[i]*A[j];
  }
}
return(sum)
\end{verbatim}

\subsection*{Part b}
Our strategy is similar to our method in part $a$.  However, with a symmetric matrix we will only store the lower-triangular part of the matrix.  $A$ stores the elements in column-wise order; but only the elements in the diagonal and lower-triangular part of the matrix.  $R$ stores the corresponding row of the elements in $A$.  And elements in $C$ indicate the element in $A$ that starts the columns of the lower triangular part of our matrix.\\
\\
We follow the same outline as above, the key difference is that when we check an element we also check it's reflection: when we check if element (i,j), we will also check element (j,i).  We include the following pseudo code:
\begin{verbatim}
sum = 0;
r = correct row;
for(int i = 0; i < c.length - 1; i++) {
  col = i;
  for(int j = c[i]; j < c[i + 1]; j++) {
    row = R[j];
    if(row == r) sum = sum + y[i]*A[j];
    if(col != row && col == r) sum = sum + y[row]*A[j];
  }
}
\end{verbatim}


\section*{Problem 6}
\subsection*{Part a}


\subsection*{Part b}
Since there are no changes to population 2 and 4, the only changes to the WSS are in the $\hat{\mu}_1$ and $\hat{\mu}_3$ terms.  We calculate the change in WSS below when we move $W_{n_W}$ from population 1 to population 3.  First we calculate the difference in WSS for population 1:
\begin{align*}
t
\end{align*}

\subsection*{Part c}
Since there are no changes to population 1 and 2, the only changes to the WSS is in $\Sigma_{i=1}^{n_Y}||Y_i - \hat{\mu}_3||^2$ and $\Sigma_{i=1}^{n_Z}||Z_i - \hat{\mu}_4||^2$.  We calculate the change in WSS below when we move $Y_{n_Y}$ from population 3 to population 4.  First we calculate the difference in WSS for population 4:
\begin{align*}
\text{Denote: } \bar{Z} = \frac{\Sigma_{i=1}^{n_Z}Z_i}{n_Z} \text{ and } \bar{Z}^* = \frac{n\bar{Z} + Y_{nY}}{n_Z + 1} \\ 
\Sigma_{i=1}^{n_Z}||Z_i - \bar{Z}^*||^2 + ||Y_{n_Y} - \bar{Z}^*||^2 - \Sigma_{i=1}^{n_Z}||Z_i - \bar{Z}||^2\\
= \Sigma_{i=1}^{n_Z}||Z_i - \bar{Z}||^2 + n_{Z}||\bar{Z} - \bar{Z}^*||^2 + ||Y_{n_Y} - \bar{Z}^*||^2 - \Sigma_{i=1}^{n_Z}||Z_i - \bar{Z}||^2\\
= n_{Z}||\bar{Z} - \bar{Z}^*||^2 + ||Y_{n_Y} - \bar{Z}^*||^2\\
= \frac{n_Z}{(n_Z + 1)^2}||\bar{Z} - Y_{n_Y}||^2 + (\frac{n_Z}{n_Z + 1})^2 ||Y_{n_Y} - \bar{Z}||^2
\end{align*}
The difference in WSS for population 3:
\begin{align*}
\text{Denote: } \bar{Y} = \frac{\Sigma_{i=1}^{n_Y}Y_i}{n_Y} \text{ and }\bar{Y}^* = \frac{n_Y \bar{Y} - Y_{n_Y}}{n_Y - 1}\\
\Sigma_{i=1}^{n_Y}||Y_i - \bar{Y}^*||^2 - ||Y_{n_Y} - \bar{Y}^*||^2 - \Sigma_{i=1}^{n_Y}||Y_i - \bar{Y}||^2 \\
= \Sigma_{i=1}^{n_Y}||Y_i - \bar{Y}||^2 + n_Y||\bar{Y} - \bar{Y}^*||^2 - ||Y_{n_Y} - \bar{Y}^*||^2 - \Sigma_{i=1}^{n_Y}||Y_i - \bar{Y}||^2\\
= n_Y||\bar{Y} - \bar{Y}^*||^2 - ||Y_{n_Y} - \bar{Y}^*||^2 \\
= \frac{n_Y}{(n_Y - 1)^2}||Y_{n_Y} - \bar{Y}||^2 - (\frac{n_Y}{n_Y - 1})^2 ||Y_{n_Y} - \bar{Y}||^2
\end{align*}

\section*{Problem 7}
See readme.txt file in /class/stat580/ashum/homework1/
\subsection*{Part a}
Code available on impact2.stat.iastate.edu under /class/stat580/ashum/homework1/temp.c
\subsection*{Part b}
Code available on impact2.stat.iastate.edu under /class/stat580/ashum/homework1/mult.c

\end{document}